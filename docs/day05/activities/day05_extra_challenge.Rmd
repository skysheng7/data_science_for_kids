---
title: "Day 5 Extra Challenge Worksheet"
bibliography: ../../references/references.bib
---

# Day 5 Extra Challenge Worksheet

## About the data

In this worksheet, we will be working with the [Nutrition Facts for McDonald's Menu](https://www.kaggle.com/datasets/mcdonalds/nutrition-facts?resource=download) data, which contains information about items sold at McDonald across 9 food categories. 

From the original dataset, we will be excluding the `Item` and `Serving Size` columns, as they are not relevant to the machine learning model we are about to build. Integrating these columns with the predictors used in this worksheet is beyond the scope of this camp.

```{r}
# Load libraries
library(tidyverse)
library(dplyr)
library(tidymodels)
set.seed(100)
```

```{r}
mcdonalds <- read_csv("data/menu.csv")
head(mcdonalds, 5)
dim(mcdonalds)
```

Each row in this dataset represents a specific item sold at McDonald's. For instance, the first row contains the nutritional information for "Egg McMuffin", categorized under "Breakfast" according to its `Category`.

### Exercise 0: Knowledge Check
For each of the cases below, determine whether it is more suitable to use **classification** or **regression**.

- Predicting whether an email is spam or not: 
- Predicting the price of a house based on its features (e.g., size, location, number of rooms): 
- Identifying different species of animals based on their physical characteristics: 
- Determining whether a movie character belongs to a Pixar film or a Disney film:

### Exercise 1: Performing Explanatory Data Analysis

#### 1.1 Inspecting Columns In Data
Before proceeding further, let's perform a brief inspection of the columns in our dataset. We will investigate the class of each column and list all the columns present in the data.

```{r}
### YOUR CODE HERE
```

#### 1.2 Removing Unwanted Columns
As discussed, let's exclude the `Item` and `Serving Size` columns from the dataset for the upcoming activities. Additionally, we will convert the `Category` column to the _factor_ class (you can use `mutate(Category = as_factor(Category))`).

```{r}
### YOUR CODE HERE
```

> **YOUR ANSWER HERE**

#### 1.3 Look into Distinct Categories
Given that each row in this dataset represents distinct items sold at McDonald's, let's determine the count of items belonging to each food category.

**<span style='color:orange'>Hint:</span>** Start by grouping all items by their `Category` and then count how many items fall into each `Category`. Your final data frame should have two columns: `Category` and `Count`.

```{r}
### YOUR CODE HERE
```

#### 1.4 Converting to Percentage
Let's add a new column named `Percentage` to indicate the proportion of items in each `Category`. Make sure that the final dataframe is sorted in descending order based on these percentages (e.g., From the highest percentage to the lowest percentage).

```{r}
### YOUR CODE HERE
```

#### 1.5 Creating a Bar Chart 
Let's create a bar chart that shows the distribution of each food category sold at McDonald's.

```{r}
options(repr.plot.width = 10, repr.plot.height = 8)
### YOUR CODE HERE
```

## Exercise 2. Building Machine Learning Model
In this exercise, we will build a classification model for Chef Ronald, who works at McDonald's headquarters. Ronald is preparing to launch his new "Mystery Item", but needs help classifying it into a specific food category. We will develop a machine learning model to classify this new item based on its nutritional information.

<br>
<img src="img/chef.png" alt="Chef" style="width: 300px; display: block; margin-left: auto; margin-right: auto;"/>

#### 2.1 Train, Test and Split
Let's use the "Train, Test, and Split" method to divide our `mcdonalds` dataset into training and testing data called `mcdonalds_train` and `mcdonalds_test`, respectively. Set the split ratio (initial_split) to $80$%. How many rows and columns of data do we have in each set?

Why do we need to split our data into train and test sets? Explain in one or two sentences.

```{r}
### YOUR CODE HERE
```

> **YOUR ANSWER HERE**

#### 2.2 Building Model and Recipe
Let's create a classification model using the k-Nearest Neighbor (k-NN) approach with $k=3$, following these guidelines:
- **Recipe**: Utilize all predictors in the dataset, excluding the `Category` column, which serves as our target variable.
- **Modeling**:  Initialize the modeling strategy with `weight_func="rectangular"`, use "kknn" as the engine, and set "classification" as the mode.

```{r}
### YOUR CODE HERE
```

#### Fit the Data into the Workflow
Let's combine the recipe and model we previously defined to fit our `mcdonalds_train` data into a workflow. Follow these steps:
1. Initialize the workflow.
2. Specify the recipe.
3. Include the model.
4. Fit the training data.

#### 2.4 Calculate Model Accuracy
Now, we will determine how accurate our model is. First, we will add a new column in our `mcdonalds_test` dataset that contains predictions made by our model. Then, we will calculate the model accuracy by evaluating how well these predictions match the actual Category values in the dataset. This accuracy assessment helps us understand how effectively our model can classify new items based on the training data it learned from.

This section of the worksheet needs you to fill in the blanks with the right answers or code. Uncomment the code and replace all `...` with what you think is the right answer.

```{r}
### REPLACE ALL ...

# validation <- predict(..., mcdonalds_test) |>
#     bind_cols(...) |>
#     rename(Category_pred = ...)
# head(validation, 5)

# acc <- validation |>
#   metrics(truth = Category, estimate = ...) |>
#   filter(.metric == ...) |>
#   select(...) |>
#   pull()

# acc
```

#### 2.5 Find the Best $k$-Value
Previously, our model was constructed using $k=3$ Now, let's explore how different values of $k$ affect our model's performance.

1. Start by running the cell below to establish our initial model.
2. In the subsequent cell, vary the first argument to test other $k$ values. For example:

```R
run_model(2, mcdonalds_train, mcdonalds_test)
run_model(3, mcdonalds_train, mcdonalds_test)
```
3. Identify and report the $k$ value that returns the highest accuracy. This will help us determine the optimal $k$ value for our classification model.

```{r}
### RUN THIS CELL

run_model <- function(k_value, train_data, test_data) {
      mcdonalds_recipe <- recipe(Category ~ ., data=train_data) |>
            step_scale(all_predictors()) |>
            step_center(all_predictors())

      knn_spec <- nearest_neighbor(weight_func = "rectangular", neighbors = k_value) |>
            set_engine("kknn") |>
            set_mode("classification")

      knn_fit <- workflow() |>
            add_recipe(mcdonalds_recipe) |>
            add_model(knn_spec) |>
            fit(data=mcdonalds_train)

      validation <- predict(knn_fit, mcdonalds_test) |>
            bind_cols(mcdonalds_test) |>
            rename(Category_pred = .pred_class)

      acc <- validation |>
            metrics(truth = Category, estimate = Category_pred) |>
            filter(.metric == "accuracy") |>
            select(.estimate) |>
            pull()
      
      acc

}
```

```{r}
### TRY CHANGING THE FIRST ARGUMENT TO DIFFERENT NUMBERS

# run_model(..., mcdonalds_train, mcdonalds_test)
```

> **YOUR ANSWER HERE**

#### 2.6 Predicting the Category of the Mystery Item
Now, it's finally time to make predictions on the Mystery Item! Using the model we defined in section 2.3, we will utilize the nutritional information of the Mystery Item to determine its `Category`. Uncomment and run the code chunks below.

```{r}
### Extracting column names from `mcdonalds_train`

# predictors_names <- colnames(mcdonalds_train)
# col_names <- predictors_names[predictors_names != "Category"]
# col_names <- as.list(col_names)
```

```{r}
### Randomly generating 21 numeric values to be used as the nutritional information of the new recipe

# set.seed(100)
# mystery_item <-  data.frame(t(runif(21, min = 0, max = 20)))
# colnames(mystery_item ) <- col_names
# mystery_item
```

```{r}
# predict(knn_fit, new_data = ...)
```

What is the category of our new mysterious recipe?
> **YOUR ANSWER HERE**

## Acknowledgements

This workshop was originally created by - [**Girls in Data Science**](https://katieburak.github.io/girls-in-DS/) workshop by Dr. Katie Burak, Jenny Lee, and Mona Zhu
